{
  "name": "test-vscode-unlimited-gpt-5-mini-server",
  "displayName": "VS Code LM Proxy Server",
  "description": "Proxies OpenAI Responses API requests to the VS Code LM API.",
  "version": "0.0.1",
  "publisher": "codex",
  "license": "MIT",
  "engines": {
    "vscode": "^1.92.0"
  },
  "categories": [
    "Other"
  ],
  "activationEvents": [
    "onStartupFinished"
  ],
  "main": "./dist/extension.js",
  "contributes": {
    "configuration": {
      "title": "LM Proxy Server",
      "properties": {
        "lmProxyServer.host": {
          "type": "string",
          "default": "127.0.0.1",
          "markdownDescription": "Hostname or IP address for the LM proxy server to bind to."
        },
        "lmProxyServer.port": {
          "type": "number",
          "default": 3141,
          "minimum": 1,
          "maximum": 65535,
          "markdownDescription": "Port number for the LM proxy server. Can also be overridden via the `VS_CODE_LM_PROXY_PORT` environment variable."
        }
      }
    }
  },
  "scripts": {
    "compile": "tsc -p ./",
    "watch": "tsc -watch -p ./",
    "lint": "eslint . --ext .ts",
    "package": "vsce package"
  },
  "devDependencies": {
    "@types/express": "^4.17.21",
    "@types/node": "^18.18.0",
    "@types/vscode": "1.92.0",
    "eslint": "^8.57.0",
    "eslint-config-prettier": "^9.1.0",
    "eslint-plugin-prettier": "^5.1.3",
    "prettier": "^3.2.5",
    "typescript": "^5.4.5",
    "vsce": "^2.15.0"
  },
  "dependencies": {
    "express": "^4.19.2"
  }
}
